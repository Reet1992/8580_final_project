# Defense on Robust physical attack against road sign classifer

Contribution : Nushrat Humaira, Reetayan Das

Fgsm detection.py detects perturbation using PCA components
Siamese_new.py: Implement Siamese network to find image similarity

# Abstarct:

Deep Learning is a subset of Machine Learning
in artificial Intelligence(AI) with networks that are capable
of learning from unstructured data. With this, we have seen
Deep Neural Networks (DNNs) to be vulnerable to adversarial
examples. These are inputs the attacker intentionally designs
for machine learning models to cause them to make a mistake.
Specially, classifier networks fell prey to perturbed examples and
were mislead into targetted or non-targetted misclassification
attacks. The effect of adversarial attack in physical world is
different, however, as physical aspects of environment are brought
into consideration.We have chosen Robust Physical Perturbation
attack for physical world,termed as RP2 as foundation for our
project. RP2 generates adversarial example for road sign images
captured in practical driving scenario. Our proposed approach
is to evaluate the robustness of physical world attack on road
sign benchmark dataset and employ various defensive methods
against the attack. Defending attacks lessens vulnerability of
classifier and is useful to gain insights into future attacks of
the same nature. We propose few novel strategies of defense as
well as apply established defense methods to make it work for
physical road sign perturbations. We analyze the effectiveness of
methods, problems encountered and possible improvements.
